{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getcwd()\n",
    "#!pip install dotmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# make sure to use position 1\n",
    "# sys.path.insert(1, \"/jet/prs/workspace/Keras-Project-Template-Jupyter\")\n",
    "sys.path.insert(1, \"/Users/mtavako1/Documents/Research/__Radiation_Therapy/Code/1_KerasLearning/Keras-Project-Template-Jupyter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.config import process_config\n",
    "from utils.dirs import create_dirs\n",
    "from utils.utils import get_args\n",
    "\n",
    "from data_loader.prostate_dist_dvh_data_loader import ProstateDistDvhDataLoader\n",
    "from models.transfer_3block_vgg16_model import Transfer3BlockVGG16Model\n",
    "from models.transfer_4block_rnn_vgg16_model import Transfer4BlockRnnVGG16Model\n",
    "\n",
    "from trainers.simple_trainer import SimpleTrainer\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the experiments dirs.\n",
      "Create the data generator.\n",
      "Start training/validating the model.\n",
      "Train on 128 samples, validate on 15 samples\n",
      "Epoch 1/2\n",
      "128/128 [==============================] - 64s 498ms/step - loss: 0.6971 - precision: 0.2781 - recall: 0.5039 - fbeta_score: 0.3517 - acc: 0.4766 - val_loss: 0.6970 - val_precision: 0.4667 - val_recall: 1.0000 - val_fbeta_score: 0.6200 - val_acc: 0.4667\n",
      "Epoch 2/2\n",
      "128/128 [==============================] - 65s 508ms/step - loss: 0.6939 - precision: 0.5281 - recall: 0.9883 - fbeta_score: 0.6729 - acc: 0.5234 - val_loss: 0.7001 - val_precision: 0.4667 - val_recall: 1.0000 - val_fbeta_score: 0.6200 - val_acc: 0.4667\n",
      "73/73 [==============================] - 16s 222ms/step\n",
      "loss: 69.27%\n",
      "precision: 52.05%\n",
      "recall: 100.00%\n",
      "fbeta_score: 68.23%\n",
      "acc: 52.05%\n",
      "Start training/validating the model.\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/2\n",
      "129/129 [==============================] - 69s 532ms/step - loss: 0.6855 - precision: 0.5271 - recall: 0.4550 - fbeta_score: 0.4372 - acc: 0.5969 - val_loss: 0.6328 - val_precision: 0.9000 - val_recall: 0.7000 - val_fbeta_score: 0.7429 - val_acc: 0.8000\n",
      "Epoch 2/2\n",
      "129/129 [==============================] - 69s 533ms/step - loss: 0.6430 - precision: 0.6783 - recall: 0.6279 - fbeta_score: 0.5963 - acc: 0.6202 - val_loss: 0.5310 - val_precision: 0.9000 - val_recall: 0.7000 - val_fbeta_score: 0.7429 - val_acc: 0.8000\n",
      "72/72 [==============================] - 18s 246ms/step\n",
      "loss: 67.26%\n",
      "precision: 64.76%\n",
      "recall: 31.48%\n",
      "fbeta_score: 41.85%\n",
      "acc: 55.56%\n",
      "Start training/validating the model.\n",
      "Train on 130 samples, validate on 15 samples\n",
      "Epoch 1/2\n",
      "130/130 [==============================] - 64s 492ms/step - loss: 0.7023 - precision: 0.4900 - recall: 0.8821 - fbeta_score: 0.5956 - acc: 0.4692 - val_loss: 0.6966 - val_precision: 0.4667 - val_recall: 1.0000 - val_fbeta_score: 0.6200 - val_acc: 0.4667\n",
      "Epoch 2/2\n",
      "130/130 [==============================] - 68s 520ms/step - loss: 0.6995 - precision: 0.5400 - recall: 0.9269 - fbeta_score: 0.6452 - acc: 0.5231 - val_loss: 0.7010 - val_precision: 0.4667 - val_recall: 1.0000 - val_fbeta_score: 0.6200 - val_acc: 0.4667\n",
      "71/71 [==============================] - 16s 230ms/step\n",
      "loss: 69.28%\n",
      "precision: 52.11%\n",
      "recall: 100.00%\n",
      "fbeta_score: 68.46%\n",
      "acc: 52.11%\n",
      "loss: 68.60% (+/- 0.95%)\n",
      "precision: 56.31% (+/- 5.98%)\n",
      "recall: 77.16% (+/- 32.30%)\n",
      "fbeta_score: 59.51% (+/- 12.49%)\n",
      "acc: 53.24% (+/- 1.64%)\n"
     ]
    }
   ],
   "source": [
    "def main(config_file):\n",
    "    # capture the config path from the run arguments\n",
    "    # then process the json configuration file\n",
    "    try:\n",
    "        config = process_config(config_file)\n",
    "        #print config\n",
    "    except:\n",
    "        assert False, \"missing or invalid arguments\"\n",
    "        \n",
    "    # create the experiments dirs\n",
    "    print('Create the experiments dirs.')\n",
    "    create_dirs([config.callbacks.tensorboard_log_dir, config.callbacks.checkpoint_dir])\n",
    "\n",
    "    print('Create the data generator.')\n",
    "    data_loader = ProstateDistDvhDataLoader(config)\n",
    "    \n",
    "    \n",
    "    # cross validation\n",
    "    cvscores = []\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=config.cross_validation.n_splits,\n",
    "        shuffle=config.cross_validation.shuffle,\n",
    "        random_state=config.cross_validation.random_state\n",
    "    )\n",
    "    \n",
    "    for train, test in kfold.split(data_loader.get_data()[0], data_loader.get_data()[1]):\n",
    "        \n",
    "        # print('Create the model.')\n",
    "        model = Transfer4BlockRnnVGG16Model(config)\n",
    "        #Transfer4BlockRnnVGG16Model(config)\n",
    "        \n",
    "        # train or train-val \n",
    "        # print('Create the trainer')\n",
    "        trainer = SimpleTrainer(model.model, data_loader.get_data(), config)\n",
    "\n",
    "        print('Start training/validating the model.')\n",
    "        # trainer.train()\n",
    "        scores = trainer.train_val(train, test)\n",
    "    \n",
    "        for metric, score in zip(model.model.metrics_names, scores):\n",
    "            print(\"%s: %.2f%%\" % (metric, score*100))\n",
    "\n",
    "        cvscores.append(scores)\n",
    "\n",
    "    means = np.mean(cvscores, axis=0)\n",
    "    stds = np.std(cvscores, axis=0)\n",
    "\n",
    "    for metric, mean, std in zip(model.model.metrics_names, means, stds):\n",
    "        print(\"%s: %.2f%% (+/- %.2f%%)\" % (metric, mean * 100, std * 100))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(\"configs/vgg16_4blocks_rnn_from_config.json\")    \n",
    "    # main(\"configs/vgg16_4blocks_rnn_from_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dotmap\n",
    "# !pip install comet_ml\n",
    "#!pip install --upgrade tensorflow tensorflow-tensorboard\n",
    "#!pip install comet_ml\n",
    "# !pip install tensorflow==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=\"/Users/mtavako1/Documents/Research/__Radiation_Therapy/Code/1_KerasLearning/Keras-Project-Template-Jupyter/experiments/2018-10-29/vgg16_3blocks_from_config/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_config_from_json(\"configs/simple_mnist_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/keunwoochoi/keras_callbacks_example\n",
    "# GAN: https://www.youtube.com/watch?v=0VPQHbMvGzg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple([1]) + (3,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model \n",
    "from keras.layers import Dense, Input \n",
    "from keras.layers.pooling import GlobalAveragePooling2D \n",
    "from keras.layers.recurrent import LSTM \n",
    "from keras.layers.wrappers import TimeDistributed \n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "video = Input(shape=(frames, channels, rows, columns)) \n",
    "cnn_base = VGG16(input_shape=(channels, rows, columns), weights=\"imagenet\", include_top=False) \n",
    "cnn_out = GlobalAveragePooling2D()(cnn_base.output) \n",
    "cnn = Model(input=cnn_base.input, output=cnn_out) \n",
    "cnn.trainable = False \n",
    "\n",
    "encoded_frames = TimeDistributed(cnn)(video) \n",
    "encoded_sequence = LSTM(256)(encoded_frames) \n",
    "hidden_layer = Dense(output_dim=1024, activation=\"relu\")(encoded_sequence) \n",
    "outputs = Dense(output_dim=classes, activation=\"softmax\")(hidden_layer) \n",
    "model = Model([video], outputs) \n",
    "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004) \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"categorical_accuracy\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
